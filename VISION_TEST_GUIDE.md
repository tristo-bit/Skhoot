# Guide de Test - Vision API

## √âtat Actuel
‚úÖ Backend en cours d'ex√©cution (port 3001)
‚úÖ Endpoint `/api/v1/files/image` impl√©ment√©
‚úÖ Code frontend impl√©ment√© avec support vision
‚úÖ Logs de d√©bogage ajout√©s

## Comment Tester

### 1. Ouvrir la Console du Navigateur
Appuie sur **F12** pour ouvrir les DevTools et va dans l'onglet **Console**.

### 2. Attacher une Image
1. Dans le chat, clique sur l'ic√¥ne de pi√®ce jointe (üìé)
2. S√©lectionne une image (JPG, PNG, GIF, etc.)
3. L'image devrait appara√Ætre comme une "chip" dans l'interface

### 3. Envoyer un Message avec l'Image
√âcris un message comme:
- "Qu'est-ce que tu vois dans cette image ?"
- "D√©cris cette image"
- "Lis le texte dans cette image" (pour OCR)

### 4. V√©rifier les Logs

Tu devrais voir dans la console:

#### Logs de Chargement d'Image
```
[ChatInterface] File references: [...]
[ChatInterface] Processing files: [...]
[ChatInterface] Checking if "image.png" is image: ext="png", isImage=true
[ChatInterface] Loading image: image.png from /path/to/image.png
[ChatInterface] Image fetch response: { ok: true, status: 200, ... }
[ChatInterface] Image blob size: XXXXX bytes, type: image/png
[ChatInterface] Base64 length: XXXXX chars
[ChatInterface] ‚úÖ Successfully loaded image file: image.png
```

#### Logs d'Envoi √† l'AI
```
[ChatInterface] Sending to AI: { messageLength: XX, imageCount: 1, ... }
[aiService] chatWithGoogle called with: { imagesCount: 1, ... }
[aiService] Using Gemini model: gemini-2.0-flash
[aiService] Adding images to current message: 1 images
[aiService] System prompt includes vision: true
[aiService] Sending request to Gemini: { hasImages: true, ... }
```

#### Logs de R√©ponse
```
[aiService] Gemini response: { hasCandidates: true, ... }
```

## Probl√®mes Possibles

### ‚ùå "Failed to read image" (404)
**Cause**: Le backend ne trouve pas le fichier
**Solution**: V√©rifie que le chemin du fichier est correct

### ‚ùå "Base64 length: 0"
**Cause**: L'image n'a pas √©t√© convertie correctement
**Solution**: V√©rifie que le blob est valide

### ‚ùå "I cannot process images"
**Causes possibles**:
1. Les images n'atteignent pas l'API (v√©rifie les logs `[aiService] Adding images`)
2. Le syst√®me prompt n'inclut pas les capacit√©s vision (v√©rifie `System prompt includes vision: true`)
3. Le mod√®le ne supporte pas la vision (v√©rifie que tu utilises `gemini-2.0-flash` ou `gemini-1.5-pro`)

## Mod√®les Supportant la Vision

### ‚úÖ Google Gemini
- gemini-2.0-flash ‚≠ê (recommand√©)
- gemini-1.5-pro
- gemini-1.5-flash

### ‚úÖ OpenAI
- gpt-4o ‚≠ê (recommand√©)
- gpt-4o-mini
- gpt-4-turbo
- gpt-4-vision-preview

### ‚úÖ Anthropic
- claude-3-5-sonnet-20241022 ‚≠ê (recommand√©)
- claude-3-opus-20240229
- claude-3-haiku-20240307

## Prochaines √âtapes

1. **Teste maintenant** avec une image
2. **Copie les logs** de la console ici si √ßa ne marche pas
3. On pourra identifier exactement o√π le probl√®me se situe dans le pipeline

## Notes Importantes

- Le backend DOIT √™tre en cours d'ex√©cution (v√©rifi√© ‚úÖ)
- Les images sont converties en base64 c√¥t√© frontend
- Le format pour Gemini est `inlineData` avec `mimeType` et `data`
- Le syst√®me prompt inclut maintenant les capacit√©s vision
